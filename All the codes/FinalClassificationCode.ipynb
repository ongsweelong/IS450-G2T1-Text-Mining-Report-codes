{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "#import plotly as px\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Word2Vec Embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ELMo Embedding\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import h5py\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import uniform  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>class</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ex wife threaten suicide recently leave wife g...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[('ex', 'NOUN'), ('wife', 'NOUN'), ('threateni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>weird get affect comp li ment come someone kno...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[('weird', 'ADJ'), ('get', 'AUX'), ('affected'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>finally almost never hear bad year ever swear ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[('finally', 'ADV'), ('almost', 'ADV'), ('neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>need help help cry hard</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[('need', 'VERB'), ('help', 'NOUN'), ('help', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lose hello name adam struggle year afraid past...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[('lost', 'VERB'), ('hello', 'INTJ'), ('name',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    lemmatized_text        class  \\\n",
       "0           0  ex wife threaten suicide recently leave wife g...      suicide   \n",
       "1           1  weird get affect comp li ment come someone kno...  non-suicide   \n",
       "2           2  finally almost never hear bad year ever swear ...  non-suicide   \n",
       "3           3                            need help help cry hard      suicide   \n",
       "4           4  lose hello name adam struggle year afraid past...      suicide   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [('ex', 'NOUN'), ('wife', 'NOUN'), ('threateni...  \n",
       "1  [('weird', 'ADJ'), ('get', 'AUX'), ('affected'...  \n",
       "2  [('finally', 'ADV'), ('almost', 'ADV'), ('neve...  \n",
       "3  [('need', 'VERB'), ('help', 'NOUN'), ('help', ...  \n",
       "4  [('lost', 'VERB'), ('hello', 'INTJ'), ('name',...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('cleaned_suicide_data.csv')\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "lemmatized_text    0\n",
       "class              0\n",
       "pos_tags           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.91      0.89      0.90     23308\n",
      "     suicide       0.89      0.91      0.90     23088\n",
      "\n",
      "    accuracy                           0.90     46396\n",
      "   macro avg       0.90      0.90      0.90     46396\n",
      "weighted avg       0.90      0.90      0.90     46396\n",
      "\n",
      "Random Forest Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.91      0.90      0.90     23195\n",
      "     suicide       0.90      0.91      0.91     23201\n",
      "\n",
      "    accuracy                           0.90     46396\n",
      "   macro avg       0.90      0.90      0.90     46396\n",
      "weighted avg       0.90      0.90      0.90     46396\n",
      "\n",
      "Best Parameters for Random Forest: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Random Forest (Fine-Tuned) Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.87      0.90      0.88     23308\n",
      "     suicide       0.90      0.86      0.88     23088\n",
      "\n",
      "    accuracy                           0.88     46396\n",
      "   macro avg       0.88      0.88      0.88     46396\n",
      "weighted avg       0.88      0.88      0.88     46396\n",
      "\n",
      "Random Forest (Fine-Tuned) Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.87      0.91      0.89     23195\n",
      "     suicide       0.90      0.87      0.88     23201\n",
      "\n",
      "    accuracy                           0.89     46396\n",
      "   macro avg       0.89      0.89      0.89     46396\n",
      "weighted avg       0.89      0.89      0.89     46396\n",
      "\n",
      "\n",
      "Naive Bayes Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.90      0.85      0.88     23308\n",
      "     suicide       0.86      0.90      0.88     23088\n",
      "\n",
      "    accuracy                           0.88     46396\n",
      "   macro avg       0.88      0.88      0.88     46396\n",
      "weighted avg       0.88      0.88      0.88     46396\n",
      "\n",
      "Naive Bayes Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.90      0.86      0.88     23195\n",
      "     suicide       0.86      0.91      0.88     23201\n",
      "\n",
      "    accuracy                           0.88     46396\n",
      "   macro avg       0.88      0.88      0.88     46396\n",
      "weighted avg       0.88      0.88      0.88     46396\n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Hyperparameters for Naive Bayes: {'alpha': 2.0}\n",
      "\n",
      "Best Naive Bayes Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.90      0.85      0.88     23308\n",
      "     suicide       0.86      0.90      0.88     23088\n",
      "\n",
      "    accuracy                           0.88     46396\n",
      "   macro avg       0.88      0.88      0.88     46396\n",
      "weighted avg       0.88      0.88      0.88     46396\n",
      "\n",
      "Best Naive Bayes Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.90      0.86      0.88     23195\n",
      "     suicide       0.86      0.91      0.88     23201\n",
      "\n",
      "    accuracy                           0.88     46396\n",
      "   macro avg       0.88      0.88      0.88     46396\n",
      "weighted avg       0.88      0.88      0.88     46396\n",
      "\n",
      "\n",
      "SVM Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.92      0.93      0.92     23308\n",
      "     suicide       0.93      0.92      0.92     23088\n",
      "\n",
      "    accuracy                           0.92     46396\n",
      "   macro avg       0.92      0.92      0.92     46396\n",
      "weighted avg       0.92      0.92      0.92     46396\n",
      "\n",
      "SVM Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.92      0.93      0.92     23195\n",
      "     suicide       0.93      0.92      0.92     23201\n",
      "\n",
      "    accuracy                           0.92     46396\n",
      "   macro avg       0.92      0.92      0.92     46396\n",
      "weighted avg       0.92      0.92      0.92     46396\n",
      "\n",
      "Best Parameters for SVM: {'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n",
      "\n",
      "SVM (Fine-Tuned) Comparison Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.92      0.93      0.93     23308\n",
      "     suicide       0.93      0.92      0.93     23088\n",
      "\n",
      "    accuracy                           0.93     46396\n",
      "   macro avg       0.93      0.93      0.93     46396\n",
      "weighted avg       0.93      0.93      0.93     46396\n",
      "\n",
      "SVM (Fine-Tuned) Fine-Tuning Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-suicide       0.92      0.94      0.93     23195\n",
      "     suicide       0.93      0.92      0.93     23201\n",
      "\n",
      "    accuracy                           0.93     46396\n",
      "   macro avg       0.93      0.93      0.93     46396\n",
      "weighted avg       0.93      0.93      0.93     46396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Additional feature extraction: Sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Check for NaN values in 'lemmatized_text'\n",
    "data['sentiment_score'] = data['lemmatized_text'].apply(lambda x: sia.polarity_scores(str(x))['compound'] if pd.notnull(x) else np.nan)\n",
    "\n",
    "# Drop rows with NaN values in 'sentiment_score'\n",
    "data = data.dropna(subset=['sentiment_score'])\n",
    "\n",
    "# Combine features\n",
    "X_text = data['lemmatized_text']\n",
    "X_sentiment = np.array(data['sentiment_score']).reshape(-1, 1)\n",
    "\n",
    "# Train-test split (60% train, 20% fine-tuning, 20% comparison)\n",
    "X_train_text, X_compare_text, X_train_sentiment, X_compare_sentiment, y_train, y_compare = train_test_split(X_text, X_sentiment, data['class'], test_size=0.4, random_state=42)\n",
    "\n",
    "# Further split the remaining data for comparison into fine-tuning and comparison\n",
    "X_fine_tune_text, X_compare_text, X_fine_tune_sentiment, X_compare_sentiment, y_fine_tune, y_compare = train_test_split(X_compare_text, X_compare_sentiment, y_compare, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature extraction: TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_text_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_compare_text_tfidf = vectorizer.transform(X_compare_text)\n",
    "X_fine_tune_text_tfidf = vectorizer.transform(X_fine_tune_text)\n",
    "\n",
    "# Combine TF-IDF features with additional features\n",
    "X_train = np.hstack((X_train_text_tfidf.toarray(), X_train_sentiment))\n",
    "X_compare = np.hstack((X_compare_text_tfidf.toarray(), X_compare_sentiment))\n",
    "X_fine_tune = np.hstack((X_fine_tune_text_tfidf.toarray(), X_fine_tune_sentiment))\n",
    "\n",
    "# Model selection and training for Random Forest\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Save Random Forest model\n",
    "joblib.dump(random_forest_model, 'random_forest_model.joblib')\n",
    "\n",
    "# Model evaluation on comparison set\n",
    "y_compare_pred_rf = random_forest_model.predict(X_compare)\n",
    "print(\"Random Forest Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_compare_pred_rf))\n",
    "\n",
    "# Model evaluation on fine-tuning set\n",
    "y_fine_tune_pred_rf = random_forest_model.predict(X_fine_tune)\n",
    "print(\"Random Forest Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_fine_tune_pred_rf))\n",
    "\n",
    "# Fine-tuning Random Forest\n",
    "# Define hyperparameters to tune\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Grid search for best parameters\n",
    "grid_search_rf = GridSearchCV(estimator=random_forest_model, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_fine_tune, y_fine_tune)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Parameters for Random Forest:\", best_params_rf)\n",
    "\n",
    "# Train Random Forest with the best parameters\n",
    "random_forest_model_best = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "random_forest_model_best.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation on comparison set with fine-tuned Random Forest\n",
    "y_compare_pred_rf_best = random_forest_model_best.predict(X_compare)\n",
    "print(\"\\nRandom Forest (Fine-Tuned) Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_compare_pred_rf_best))\n",
    "\n",
    "# Model evaluation on fine-tuning set with fine-tuned Random Forest\n",
    "y_fine_tune_pred_rf_best = random_forest_model_best.predict(X_fine_tune)\n",
    "print(\"Random Forest (Fine-Tuned) Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_fine_tune_pred_rf_best))\n",
    "\n",
    "# Combine TF-IDF features with additional features for Naive Bayes\n",
    "X_train_nb = np.hstack((X_train_text_tfidf.toarray(), X_train_sentiment + 1))  # Add 1 to ensure non-negative values\n",
    "X_compare_nb = np.hstack((X_compare_text_tfidf.toarray(), X_compare_sentiment + 1))\n",
    "X_fine_tune_nb = np.hstack((X_fine_tune_text_tfidf.toarray(), X_fine_tune_sentiment + 1))\n",
    "\n",
    "# Model selection and training for Naive Bayes\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train_nb, y_train)\n",
    "\n",
    "# Save Naive Bayes model\n",
    "joblib.dump(naive_bayes_model, 'naive_bayes_model.joblib')\n",
    "\n",
    "# Model evaluation on comparison set with Naive Bayes\n",
    "y_compare_pred_nb = naive_bayes_model.predict(X_compare_nb)\n",
    "print(\"\\nNaive Bayes Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_compare_pred_nb))\n",
    "\n",
    "# Model evaluation on fine-tuning set with Naive Bayes\n",
    "y_fine_tune_pred_nb = naive_bayes_model.predict(X_fine_tune_nb)\n",
    "print(\"Naive Bayes Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_fine_tune_pred_nb))\n",
    "\n",
    "# Fine-tuning Naive Bayes\n",
    "# Define hyperparameters to tune\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0]  # Add more values for alpha if needed\n",
    "}\n",
    "\n",
    "# Grid search for best parameters\n",
    "grid_search_nb = GridSearchCV(estimator=MultinomialNB(), param_grid=param_grid_nb, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search_nb.fit(X_fine_tune_nb, y_fine_tune)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_nb = grid_search_nb.best_params_\n",
    "print(\"Best Hyperparameters for Naive Bayes:\", best_params_nb)\n",
    "\n",
    "# Retrain the model using the best hyperparameters\n",
    "best_nb_model = MultinomialNB(alpha=best_params_nb['alpha'])\n",
    "best_nb_model.fit(X_train_nb, y_train)\n",
    "\n",
    "# Save the best Naive Bayes model\n",
    "joblib.dump(best_nb_model, 'best_naive_bayes_model.joblib')\n",
    "\n",
    "# Model evaluation on comparison set using the best model\n",
    "y_pred_best_nb = best_nb_model.predict(X_compare_nb)\n",
    "print(\"\\nBest Naive Bayes Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_pred_best_nb))\n",
    "\n",
    "# Model evaluation on fine-tuning set using the best model\n",
    "y_pred_best_nb_fine_tune = best_nb_model.predict(X_fine_tune_nb)\n",
    "print(\"Best Naive Bayes Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_pred_best_nb_fine_tune))\n",
    "\n",
    "# Model selection and training for SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save SVM model\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Model evaluation on comparison set with SVM\n",
    "y_compare_pred_svm = svm_model.predict(X_compare)\n",
    "print(\"\\nSVM Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_compare_pred_svm))\n",
    "\n",
    "# Model evaluation on fine-tuning set with SVM\n",
    "y_fine_tune_pred_svm = svm_model.predict(X_fine_tune)\n",
    "print(\"SVM Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_fine_tune_pred_svm))\n",
    "\n",
    "# Fine-tuning SVM\n",
    "# Define hyperparameters to tune\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],  # Reduce the number of values\n",
    "    'kernel': ['linear', 'rbf'],  # Limit the kernel choices\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Randomized search for best parameters\n",
    "random_search_svm = RandomizedSearchCV(estimator=svm_model, param_distributions=param_grid_svm, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "random_search_svm.fit(X_fine_tune, y_fine_tune)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_svm = random_search_svm.best_params_\n",
    "print(\"Best Parameters for SVM:\", best_params_svm)\n",
    "\n",
    "# Train SVM with the best parameters\n",
    "svm_model_best = SVC(**best_params_svm)\n",
    "svm_model_best.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation on comparison set with fine-tuned SVM\n",
    "y_compare_pred_svm_best = svm_model_best.predict(X_compare)\n",
    "print(\"\\nSVM (Fine-Tuned) Comparison Set Classification Report:\")\n",
    "print(classification_report(y_compare, y_compare_pred_svm_best))\n",
    "\n",
    "# Model evaluation on fine-tuning set with fine-tuned SVM\n",
    "y_fine_tune_pred_svm_best = svm_model_best.predict(X_fine_tune)\n",
    "print(\"SVM (Fine-Tuned) Fine-Tuning Set Classification Report:\")\n",
    "print(classification_report(y_fine_tune, y_fine_tune_pred_svm_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Predictions:\n",
      "['non-suicide' 'non-suicide' 'non-suicide' 'non-suicide' 'non-suicide'\n",
      " 'non-suicide' 'non-suicide' 'non-suicide' 'non-suicide' 'non-suicide'\n",
      " 'non-suicide']\n",
      "\n",
      "Naive Bayes Predictions:\n",
      "['suicide' 'suicide' 'suicide' 'suicide' 'suicide' 'suicide' 'suicide'\n",
      " 'suicide' 'suicide' 'suicide' 'non-suicide']\n",
      "\n",
      "SVM Predictions:\n",
      "['suicide' 'non-suicide' 'suicide' 'suicide' 'non-suicide' 'non-suicide'\n",
      " 'non-suicide' 'suicide' 'suicide' 'suicide' 'non-suicide']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I can't go on like this anymore. The pain is unbearable.\",\n",
    "    \"It feels like there's no way out of this darkness. I'm so tired of fighting.\",\n",
    "    \"I don't see any reason to keep living. Everything just hurts too much.\",\n",
    "    \"I feel like I'm a burden to everyone around me. Maybe it's better if I just disappear.\",\n",
    "    \"I've been thinking a lot about ending it all. Maybe that's the only way to find peace.\",\n",
    "    \"Nobody would even miss me if I were gone. I don't belong here.\",\n",
    "    \"The world would be better off without me. I'm just a waste of space.\",\n",
    "    \"I can't shake this feeling of hopelessness. Maybe death is the only way to escape.\",\n",
    "    \"I've thought about how I would do it. Maybe tonight's the night.\",\n",
    "    \"I'm so alone. I don't think anyone understands how much pain I'm in.\",\n",
    "    \"I want to live\"\n",
    "]\n",
    "\n",
    "# Preprocess and vectorize the sentences using the TF-IDF vectorizer for Naive Bayes\n",
    "sentences_tfidf = vectorizer.transform(sentences)\n",
    "sentiments = [sia.polarity_scores(sentence)['compound'] for sentence in sentences]\n",
    "\n",
    "# Combine TF-IDF features with sentiment scores for Random Forest\n",
    "X_sentences = np.hstack((sentences_tfidf.toarray(), np.array(sentiments).reshape(-1, 1) + 1))\n",
    "\n",
    "\n",
    "\n",
    "# Use Random Forest model for prediction\n",
    "predictions_rf = random_forest_model_best.predict(X_sentences)\n",
    "print(\"\\nRandom Forest Predictions:\")\n",
    "print(predictions_rf)\n",
    "\n",
    "# Use NB for prediction\n",
    "predictions_nb = best_nb_model.predict(X_sentences)\n",
    "print(\"\\nNaive Bayes Predictions:\")\n",
    "print(predictions_nb)\n",
    "\n",
    "# Use SVM model for prediction\n",
    "predictions_svm = svm_model_best.predict(X_sentences)\n",
    "print(\"\\nSVM Predictions:\")\n",
    "print(predictions_svm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model_best.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save SVM-best model\n",
    "joblib.dump(svm_model_best, 'svm_model_best.joblib')\n",
    "\n",
    "# Save Random Forest Best model\n",
    "joblib.dump(random_forest_model_best, 'random_forest_model_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
